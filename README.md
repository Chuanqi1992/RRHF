# RRHF
Aligning Human Preferences and Language Models without tears
